{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import dython\n",
    "import pickle\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "from dython.nominal import associations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Dst Port</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Tot Fwd Pkts</th>\n",
       "      <th>Tot Bwd Pkts</th>\n",
       "      <th>TotLen Fwd Pkts</th>\n",
       "      <th>TotLen Bwd Pkts</th>\n",
       "      <th>Fwd Pkt Len Max</th>\n",
       "      <th>Fwd Pkt Len Min</th>\n",
       "      <th>Fwd Pkt Len Mean</th>\n",
       "      <th>...</th>\n",
       "      <th>Fwd Seg Size Min</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3389</td>\n",
       "      <td>1665875</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>1128</td>\n",
       "      <td>1581.0</td>\n",
       "      <td>661</td>\n",
       "      <td>0</td>\n",
       "      <td>141.00</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>67765</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>94</td>\n",
       "      <td>268.0</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>47.00</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>213190</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>41967</td>\n",
       "      <td>86370853</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86400000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86400000.0</td>\n",
       "      <td>86400000.0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>5113386</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>97</td>\n",
       "      <td>231.0</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>24.25</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Dst Port  Flow Duration  Tot Fwd Pkts  Tot Bwd Pkts  \\\n",
       "0           0      3389        1665875             8             7   \n",
       "1           1        53          67765             2             2   \n",
       "2           2         0         213190             5             0   \n",
       "3           3     41967       86370853             2             0   \n",
       "4           4        80        5113386             4             4   \n",
       "\n",
       "   TotLen Fwd Pkts  TotLen Bwd Pkts  Fwd Pkt Len Max  Fwd Pkt Len Min  \\\n",
       "0             1128           1581.0              661                0   \n",
       "1               94            268.0               47               47   \n",
       "2                0              0.0                0                0   \n",
       "3                0              0.0                0                0   \n",
       "4               97            231.0               97                0   \n",
       "\n",
       "   Fwd Pkt Len Mean  ...  Fwd Seg Size Min  Active Mean  Active Std  \\\n",
       "0            141.00  ...                20          0.0         0.0   \n",
       "1             47.00  ...                 8          0.0         0.0   \n",
       "2              0.00  ...                 0          0.0         0.0   \n",
       "3              0.00  ...                20          0.0         0.0   \n",
       "4             24.25  ...                20          0.0         0.0   \n",
       "\n",
       "   Active Max  Active Min   Idle Mean  Idle Std    Idle Max    Idle Min  \\\n",
       "0         0.0         0.0         0.0       0.0         0.0         0.0   \n",
       "1         0.0         0.0         0.0       0.0         0.0         0.0   \n",
       "2         0.0         0.0         0.0       0.0         0.0         0.0   \n",
       "3         0.0         0.0  86400000.0       0.0  86400000.0  86400000.0   \n",
       "4         0.0         0.0         0.0       0.0         0.0         0.0   \n",
       "\n",
       "    Label  \n",
       "0  Benign  \n",
       "1  Benign  \n",
       "2  Benign  \n",
       "3  Benign  \n",
       "4  Benign  \n",
       "\n",
       "[5 rows x 74 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cyber = pd.read_csv(\"../data/cic_ids_2018.csv\")\n",
    "cyber.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 246730 entries, 0 to 246729\n",
      "Data columns (total 74 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   Unnamed: 0         246730 non-null  int64  \n",
      " 1   Dst Port           246730 non-null  int64  \n",
      " 2   Flow Duration      246730 non-null  int64  \n",
      " 3   Tot Fwd Pkts       246730 non-null  int64  \n",
      " 4   Tot Bwd Pkts       246730 non-null  int64  \n",
      " 5   TotLen Fwd Pkts    246730 non-null  int64  \n",
      " 6   TotLen Bwd Pkts    246730 non-null  float64\n",
      " 7   Fwd Pkt Len Max    246730 non-null  int64  \n",
      " 8   Fwd Pkt Len Min    246730 non-null  int64  \n",
      " 9   Fwd Pkt Len Mean   246730 non-null  float64\n",
      " 10  Fwd Pkt Len Std    246730 non-null  float64\n",
      " 11  Bwd Pkt Len Max    246730 non-null  int64  \n",
      " 12  Bwd Pkt Len Min    246730 non-null  int64  \n",
      " 13  Bwd Pkt Len Mean   246730 non-null  float64\n",
      " 14  Bwd Pkt Len Std    246730 non-null  float64\n",
      " 15  Flow IAT Mean      246730 non-null  float64\n",
      " 16  Flow IAT Std       246730 non-null  float64\n",
      " 17  Flow IAT Max       246730 non-null  float64\n",
      " 18  Flow IAT Min       246730 non-null  float64\n",
      " 19  Fwd IAT Tot        246730 non-null  float64\n",
      " 20  Fwd IAT Mean       246730 non-null  float64\n",
      " 21  Fwd IAT Std        246730 non-null  float64\n",
      " 22  Fwd IAT Max        246730 non-null  float64\n",
      " 23  Fwd IAT Min        246730 non-null  float64\n",
      " 24  Bwd IAT Tot        246730 non-null  float64\n",
      " 25  Bwd IAT Mean       246730 non-null  float64\n",
      " 26  Bwd IAT Std        246730 non-null  float64\n",
      " 27  Bwd IAT Max        246730 non-null  float64\n",
      " 28  Bwd IAT Min        246730 non-null  float64\n",
      " 29  Fwd PSH Flags      246730 non-null  int64  \n",
      " 30  Bwd PSH Flags      246730 non-null  int64  \n",
      " 31  Fwd URG Flags      246730 non-null  int64  \n",
      " 32  Bwd URG Flags      246730 non-null  int64  \n",
      " 33  Fwd Header Len     246730 non-null  int64  \n",
      " 34  Bwd Header Len     246730 non-null  int64  \n",
      " 35  Fwd Pkts/s         246730 non-null  float64\n",
      " 36  Bwd Pkts/s         246730 non-null  float64\n",
      " 37  Pkt Len Min        246730 non-null  int64  \n",
      " 38  Pkt Len Max        246730 non-null  int64  \n",
      " 39  Pkt Len Mean       246730 non-null  float64\n",
      " 40  Pkt Len Std        246730 non-null  float64\n",
      " 41  Pkt Len Var        246730 non-null  float64\n",
      " 42  FIN Flag Cnt       246730 non-null  int64  \n",
      " 43  SYN Flag Cnt       246730 non-null  int64  \n",
      " 44  RST Flag Cnt       246730 non-null  int64  \n",
      " 45  ACK Flag Cnt       246730 non-null  int64  \n",
      " 46  URG Flag Cnt       246730 non-null  int64  \n",
      " 47  CWE Flag Count     246730 non-null  int64  \n",
      " 48  ECE Flag Cnt       246730 non-null  int64  \n",
      " 49  Pkt Size Avg       246730 non-null  float64\n",
      " 50  Fwd Seg Size Avg   246730 non-null  float64\n",
      " 51  Bwd Seg Size Avg   246730 non-null  float64\n",
      " 52  Fwd Byts/b Avg     246730 non-null  int64  \n",
      " 53  Fwd Pkts/b Avg     246730 non-null  int64  \n",
      " 54  Fwd Blk Rate Avg   246730 non-null  int64  \n",
      " 55  Bwd Byts/b Avg     246730 non-null  int64  \n",
      " 56  Bwd Pkts/b Avg     246730 non-null  int64  \n",
      " 57  Bwd Blk Rate Avg   246730 non-null  int64  \n",
      " 58  Subflow Fwd Pkts   246730 non-null  int64  \n",
      " 59  Subflow Fwd Byts   246730 non-null  int64  \n",
      " 60  Subflow Bwd Pkts   246730 non-null  int64  \n",
      " 61  Subflow Bwd Byts   246730 non-null  int64  \n",
      " 62  Init Bwd Win Byts  246730 non-null  int64  \n",
      " 63  Fwd Act Data Pkts  246730 non-null  int64  \n",
      " 64  Fwd Seg Size Min   246730 non-null  int64  \n",
      " 65  Active Mean        246730 non-null  float64\n",
      " 66  Active Std         246730 non-null  float64\n",
      " 67  Active Max         246730 non-null  float64\n",
      " 68  Active Min         246730 non-null  float64\n",
      " 69  Idle Mean          246730 non-null  float64\n",
      " 70  Idle Std           246730 non-null  float64\n",
      " 71  Idle Max           246730 non-null  float64\n",
      " 72  Idle Min           246730 non-null  float64\n",
      " 73  Label              246730 non-null  object \n",
      "dtypes: float64(35), int64(38), object(1)\n",
      "memory usage: 139.3+ MB\n"
     ]
    }
   ],
   "source": [
    "cyber.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0       0\n",
       "Dst Port         0\n",
       "Flow Duration    0\n",
       "Tot Fwd Pkts     0\n",
       "Tot Bwd Pkts     0\n",
       "                ..\n",
       "Idle Mean        0\n",
       "Idle Std         0\n",
       "Idle Max         0\n",
       "Idle Min         0\n",
       "Label            0\n",
       "Length: 74, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cyber.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bwd IAT Tot', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min']\n"
     ]
    }
   ],
   "source": [
    "start = []\n",
    "for col in cyber.columns:\n",
    "        if col[:7] == \"Bwd IAT\": \n",
    "                start.append(col)\n",
    "print(start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyber = cyber.replace(0, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Dst Port</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Tot Fwd Pkts</th>\n",
       "      <th>Tot Bwd Pkts</th>\n",
       "      <th>TotLen Fwd Pkts</th>\n",
       "      <th>TotLen Bwd Pkts</th>\n",
       "      <th>Fwd Pkt Len Max</th>\n",
       "      <th>Fwd Pkt Len Min</th>\n",
       "      <th>Fwd Pkt Len Mean</th>\n",
       "      <th>...</th>\n",
       "      <th>Fwd Seg Size Min</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3389.0</td>\n",
       "      <td>1665875.0</td>\n",
       "      <td>8</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1128.0</td>\n",
       "      <td>1581.0</td>\n",
       "      <td>661.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.00</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>67765.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>47.00</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>213190.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>41967.0</td>\n",
       "      <td>86370853.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86400000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86400000.0</td>\n",
       "      <td>86400000.0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>5113386.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.25</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Dst Port  Flow Duration  Tot Fwd Pkts  Tot Bwd Pkts  \\\n",
       "0         0.0    3389.0      1665875.0             8           7.0   \n",
       "1         1.0      53.0        67765.0             2           2.0   \n",
       "2         2.0       0.0       213190.0             5           0.0   \n",
       "3         3.0   41967.0     86370853.0             2           0.0   \n",
       "4         4.0      80.0      5113386.0             4           4.0   \n",
       "\n",
       "   TotLen Fwd Pkts  TotLen Bwd Pkts  Fwd Pkt Len Max  Fwd Pkt Len Min  \\\n",
       "0           1128.0           1581.0            661.0              0.0   \n",
       "1             94.0            268.0             47.0             47.0   \n",
       "2              0.0              0.0              0.0              0.0   \n",
       "3              0.0              0.0              0.0              0.0   \n",
       "4             97.0            231.0             97.0              0.0   \n",
       "\n",
       "   Fwd Pkt Len Mean  ...  Fwd Seg Size Min  Active Mean  Active Std  \\\n",
       "0            141.00  ...              20.0          0.0         0.0   \n",
       "1             47.00  ...               8.0          0.0         0.0   \n",
       "2              0.00  ...               0.0          0.0         0.0   \n",
       "3              0.00  ...              20.0          0.0         0.0   \n",
       "4             24.25  ...              20.0          0.0         0.0   \n",
       "\n",
       "   Active Max  Active Min   Idle Mean  Idle Std    Idle Max    Idle Min  \\\n",
       "0         0.0         0.0         0.0       0.0         0.0         0.0   \n",
       "1         0.0         0.0         0.0       0.0         0.0         0.0   \n",
       "2         0.0         0.0         0.0       0.0         0.0         0.0   \n",
       "3         0.0         0.0  86400000.0       0.0  86400000.0  86400000.0   \n",
       "4         0.0         0.0         0.0       0.0         0.0         0.0   \n",
       "\n",
       "    Label  \n",
       "0  Benign  \n",
       "1  Benign  \n",
       "2  Benign  \n",
       "3  Benign  \n",
       "4  Benign  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cyber.dropna(how = \"all\", axis =1,inplace = True )\n",
    "cyber.fillna(0, inplace = True)\n",
    "cyber.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(246730, 66)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cyber.dropna(how = \"all\", axis =0,inplace = True )\n",
    "cyber.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= cyber.drop(['Label',\"Unnamed: 0\"], axis =1)\n",
    "y =cyber[\"Label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "np.random.seed(42)\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bwd IAT Tot', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('../data/cic_ids_2018.csv')\n",
    "\n",
    "# Handle missing values by dropping rows with any None or NaN values\n",
    "data = data.dropna()\n",
    "\n",
    "# Encode categorical labels\n",
    "label_encoder = LabelEncoder()\n",
    "data['Label'] = label_encoder.fit_transform(data['Label'])\n",
    "\n",
    "# Separate features and labels\n",
    "X = data.drop('Label', axis=1)\n",
    "y = data['Label']\n",
    "\n",
    "# Drop columns with all zero values\n",
    "X = X.loc[:, (X != 0).any(axis=0)]\n",
    "\n",
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Print the columns that start with \"Bwd IAT\"\n",
    "start = []\n",
    "for col in X.columns:\n",
    "    if col[:7] == \"Bwd IAT\":\n",
    "        start.append(col)\n",
    "print(start)\n",
    "\n",
    "# Handle missing values again (if any)\n",
    "X.dropna(how='all', axis=1, inplace=True)\n",
    "X.fillna(0, inplace=True)\n",
    "X.dropna(how='all', axis=0, inplace=True)\n",
    "\n",
    "# Convert X_scaled back to DataFrame for further processing\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sanjanathyady/Desktop/project-2/.venv/lib/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Define the generator model\n",
    "def build_generator():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(128, activation='relu', input_dim=100))\n",
    "    model.add(layers.Dense(256, activation='relu'))\n",
    "    model.add(layers.Dense(512, activation='relu'))\n",
    "    model.add(layers.Dense(X.shape[1], activation='tanh'))\n",
    "    return model\n",
    "\n",
    "# Define the discriminator model (critic in WGAN)\n",
    "def build_critic():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(512, activation='relu', input_dim=X.shape[1]))\n",
    "    model.add(layers.Dense(256, activation='relu'))\n",
    "    model.add(layers.Dense(1))\n",
    "    return model\n",
    "\n",
    "# Build the generator and critic\n",
    "generator = build_generator()\n",
    "critic = build_critic()\n",
    "\n",
    "# Define the WGAN class\n",
    "class WGAN(tf.keras.Model):\n",
    "    def __init__(self, generator, critic, gp_weight=10.0):\n",
    "        super(WGAN, self).__init__()\n",
    "        self.generator = generator\n",
    "        self.critic = critic\n",
    "        self.gp_weight = gp_weight\n",
    "\n",
    "    def compile(self, g_optimizer, c_optimizer, g_loss_fn, c_loss_fn):\n",
    "        super(WGAN, self).compile()\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.c_optimizer = c_optimizer\n",
    "        self.g_loss_fn = g_loss_fn\n",
    "        self.c_loss_fn = c_loss_fn\n",
    "\n",
    "    def gradient_penalty(self, batch_size, real_data, fake_data):\n",
    "        alpha = tf.random.normal([batch_size, 1], 0.0, 1.0)\n",
    "        diff = fake_data - real_data\n",
    "        interpolated = real_data + alpha * diff\n",
    "\n",
    "        with tf.GradientTape() as gp_tape:\n",
    "            gp_tape.watch(interpolated)\n",
    "            pred = self.critic(interpolated, training=True)\n",
    "\n",
    "        grads = gp_tape.gradient(pred, [interpolated])[0]\n",
    "        norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1]))\n",
    "        gp = tf.reduce_mean((norm - 1.0) ** 2)\n",
    "        return gp\n",
    "\n",
    "    def train_step(self, real_data):\n",
    "        batch_size = tf.shape(real_data)[0]\n",
    "        for _ in range(5):\n",
    "            noise = tf.random.normal([batch_size, 100])\n",
    "            with tf.GradientTape() as c_tape:\n",
    "                fake_data = self.generator(noise, training=True)\n",
    "                real_output = self.critic(real_data, training=True)\n",
    "                fake_output = self.critic(fake_data, training=True)\n",
    "                c_loss = self.c_loss_fn(real_output, fake_output)\n",
    "                gp = self.gradient_penalty(batch_size, real_data, fake_data)\n",
    "                c_loss += gp * self.gp_weight\n",
    "\n",
    "            c_grads = c_tape.gradient(c_loss, self.critic.trainable_variables)\n",
    "            self.c_optimizer.apply_gradients(zip(c_grads, self.critic.trainable_variables))\n",
    "\n",
    "        noise = tf.random.normal([batch_size, 100])\n",
    "        with tf.GradientTape() as g_tape:\n",
    "            fake_data = self.generator(noise, training=True)\n",
    "            fake_output = self.critic(fake_data, training=True)\n",
    "            g_loss = self.g_loss_fn(fake_output)\n",
    "\n",
    "        g_grads = g_tape.gradient(g_loss, self.generator.trainable_variables)\n",
    "        self.g_optimizer.apply_gradients(zip(g_grads, self.generator.trainable_variables))\n",
    "\n",
    "        return {\"c_loss\": c_loss, \"g_loss\": g_loss}\n",
    "\n",
    "# Define the loss functions\n",
    "def generator_loss(fake_output):\n",
    "    return -tf.reduce_mean(fake_output)\n",
    "\n",
    "def critic_loss(real_output, fake_output):\n",
    "    return tf.reduce_mean(fake_output) - tf.reduce_mean(real_output)\n",
    "\n",
    "# Instantiate the WGAN model\n",
    "wgan = WGAN(generator, critic)\n",
    "\n",
    "# Compile the WGAN model\n",
    "wgan.compile(\n",
    "    g_optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.5, beta_2=0.9),\n",
    "    c_optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.5, beta_2=0.9),\n",
    "    g_loss_fn=generator_loss,\n",
    "    c_loss_fn=critic_loss\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Epoch: 1000\n",
      "Epoch: 2000\n",
      "Epoch: 3000\n",
      "Epoch: 4000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, X_scaled\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], batch_size)\n\u001b[1;32m      8\u001b[0m real_data \u001b[38;5;241m=\u001b[39m X_scaled[idx]\n\u001b[0;32m----> 9\u001b[0m \u001b[43mwgan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreal_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m1000\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[27], line 67\u001b[0m, in \u001b[0;36mWGAN.train_step\u001b[0;34m(self, real_data)\u001b[0m\n\u001b[1;32m     64\u001b[0m         c_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m gp \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgp_weight\n\u001b[1;32m     66\u001b[0m     c_grads \u001b[38;5;241m=\u001b[39m c_tape\u001b[38;5;241m.\u001b[39mgradient(c_loss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcritic\u001b[38;5;241m.\u001b[39mtrainable_variables)\n\u001b[0;32m---> 67\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_optimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mc_grads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcritic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m noise \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal([batch_size, \u001b[38;5;241m100\u001b[39m])\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m g_tape:\n",
      "File \u001b[0;32m~/Desktop/project-2/.venv/lib/python3.9/site-packages/keras/src/optimizers/base_optimizer.py:344\u001b[0m, in \u001b[0;36mBaseOptimizer.apply_gradients\u001b[0;34m(self, grads_and_vars)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_gradients\u001b[39m(\u001b[38;5;28mself\u001b[39m, grads_and_vars):\n\u001b[1;32m    343\u001b[0m     grads, trainable_variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mgrads_and_vars)\n\u001b[0;32m--> 344\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;66;03m# Return iterations for compat with tf.keras.\u001b[39;00m\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterations\n",
      "File \u001b[0;32m~/Desktop/project-2/.venv/lib/python3.9/site-packages/keras/src/optimizers/base_optimizer.py:409\u001b[0m, in \u001b[0;36mBaseOptimizer.apply\u001b[0;34m(self, grads, trainable_variables)\u001b[0m\n\u001b[1;32m    406\u001b[0m     grads \u001b[38;5;241m=\u001b[39m [g \u001b[38;5;28;01mif\u001b[39;00m g \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m g \u001b[38;5;241m/\u001b[39m scale \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m grads]\n\u001b[1;32m    408\u001b[0m \u001b[38;5;66;03m# Apply gradient updates.\u001b[39;00m\n\u001b[0;32m--> 409\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend_apply_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;66;03m# Apply variable constraints after applying gradients.\u001b[39;00m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m variable \u001b[38;5;129;01min\u001b[39;00m trainable_variables:\n",
      "File \u001b[0;32m~/Desktop/project-2/.venv/lib/python3.9/site-packages/keras/src/optimizers/base_optimizer.py:472\u001b[0m, in \u001b[0;36mBaseOptimizer._backend_apply_gradients\u001b[0;34m(self, grads, trainable_variables)\u001b[0m\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_weight_decay(trainable_variables)\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;66;03m# Run update step.\u001b[39;00m\n\u001b[0;32m--> 472\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend_update_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    473\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_ema:\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_variables_moving_average(\n\u001b[1;32m    478\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainable_variables\n\u001b[1;32m    479\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/project-2/.venv/lib/python3.9/site-packages/keras/src/backend/tensorflow/optimizer.py:120\u001b[0m, in \u001b[0;36mTFOptimizer._backend_update_step\u001b[0;34m(self, grads, trainable_variables, learning_rate)\u001b[0m\n\u001b[1;32m    118\u001b[0m grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(grads, trainable_variables))\n\u001b[1;32m    119\u001b[0m grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_all_reduce_sum_gradients(grads_and_vars)\n\u001b[0;32m--> 120\u001b[0m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__internal__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaybe_merge_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_distributed_tf_update_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_distribution_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads_and_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/project-2/.venv/lib/python3.9/site-packages/tensorflow/python/distribute/merge_call_interim.py:51\u001b[0m, in \u001b[0;36mmaybe_merge_call\u001b[0;34m(fn, strategy, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Maybe invoke `fn` via `merge_call` which may or may not be fulfilled.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03mThe caller of this utility function requests to invoke `fn` via `merge_call`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;124;03m  The return value of the `fn` call.\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m strategy_supports_no_merge_call():\n\u001b[0;32m---> 51\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m distribute_lib\u001b[38;5;241m.\u001b[39mget_replica_context()\u001b[38;5;241m.\u001b[39mmerge_call(\n\u001b[1;32m     54\u001b[0m       fn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Desktop/project-2/.venv/lib/python3.9/site-packages/keras/src/backend/tensorflow/optimizer.py:134\u001b[0m, in \u001b[0;36mTFOptimizer._distributed_tf_update_step\u001b[0;34m(self, distribution, grads_and_vars, learning_rate)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_step(grad, var, learning_rate)\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m grad, var \u001b[38;5;129;01min\u001b[39;00m grads_and_vars:\n\u001b[0;32m--> 134\u001b[0m     \u001b[43mdistribution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextended\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mapply_grad_to_update_var\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/project-2/.venv/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3005\u001b[0m, in \u001b[0;36mStrategyExtendedV2.update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   3002\u001b[0m   fn \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[1;32m   3003\u001b[0m       fn, autograph_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   3004\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy()\u001b[38;5;241m.\u001b[39mscope():\n\u001b[0;32m-> 3005\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3006\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3007\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_replica_ctx_update(\n\u001b[1;32m   3008\u001b[0m       var, fn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs, group\u001b[38;5;241m=\u001b[39mgroup)\n",
      "File \u001b[0;32m~/Desktop/project-2/.venv/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:4075\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   4072\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update\u001b[39m(\u001b[38;5;28mself\u001b[39m, var, fn, args, kwargs, group):\n\u001b[1;32m   4073\u001b[0m   \u001b[38;5;66;03m# The implementations of _update() and _update_non_slot() are identical\u001b[39;00m\n\u001b[1;32m   4074\u001b[0m   \u001b[38;5;66;03m# except _update() passes `var` as the first argument to `fn()`.\u001b[39;00m\n\u001b[0;32m-> 4075\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_non_slot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/project-2/.venv/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:4081\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._update_non_slot\u001b[0;34m(self, colocate_with, fn, args, kwargs, should_group)\u001b[0m\n\u001b[1;32m   4077\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_non_slot\u001b[39m(\u001b[38;5;28mself\u001b[39m, colocate_with, fn, args, kwargs, should_group):\n\u001b[1;32m   4078\u001b[0m   \u001b[38;5;66;03m# TODO(josh11b): Figure out what we should be passing to UpdateContext()\u001b[39;00m\n\u001b[1;32m   4079\u001b[0m   \u001b[38;5;66;03m# once that value is used for something.\u001b[39;00m\n\u001b[1;32m   4080\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m UpdateContext(colocate_with):\n\u001b[0;32m-> 4081\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4082\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m should_group:\n\u001b[1;32m   4083\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Desktop/project-2/.venv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:596\u001b[0m, in \u001b[0;36mcall_with_unspecified_conversion_status.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    595\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mControlStatusCtx(status\u001b[38;5;241m=\u001b[39mag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mUNSPECIFIED):\n\u001b[0;32m--> 596\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/project-2/.venv/lib/python3.9/site-packages/keras/src/backend/tensorflow/optimizer.py:131\u001b[0m, in \u001b[0;36mTFOptimizer._distributed_tf_update_step.<locals>.apply_grad_to_update_var\u001b[0;34m(var, grad, learning_rate)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_grad_to_update_var\u001b[39m(var, grad, learning_rate):\n\u001b[0;32m--> 131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/project-2/.venv/lib/python3.9/site-packages/keras/src/optimizers/adam.py:145\u001b[0m, in \u001b[0;36mAdam.update_step\u001b[0;34m(self, gradient, variable, learning_rate)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massign(v_hat, ops\u001b[38;5;241m.\u001b[39mmaximum(v_hat, v))\n\u001b[1;32m    144\u001b[0m     v \u001b[38;5;241m=\u001b[39m v_hat\n\u001b[0;32m--> 145\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massign_sub\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvariable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdivide\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultiply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepsilon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/project-2/.venv/lib/python3.9/site-packages/keras/src/backend/tensorflow/optimizer.py:72\u001b[0m, in \u001b[0;36mTFOptimizer.assign_sub\u001b[0;34m(self, variable, value)\u001b[0m\n\u001b[1;32m     70\u001b[0m     variable\u001b[38;5;241m.\u001b[39mscatter_sub(value)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 72\u001b[0m     \u001b[43mvariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massign_sub\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/project-2/.venv/lib/python3.9/site-packages/tensorflow/python/ops/weak_tensor_ops.py:142\u001b[0m, in \u001b[0;36mweak_tensor_binary_op_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    141\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mis_auto_dtype_conversion_enabled():\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m   bound_arguments \u001b[38;5;241m=\u001b[39m signature\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    144\u001b[0m   bound_arguments\u001b[38;5;241m.\u001b[39mapply_defaults()\n",
      "File \u001b[0;32m~/Desktop/project-2/.venv/lib/python3.9/site-packages/tensorflow/python/ops/resource_variable_ops.py:1017\u001b[0m, in \u001b[0;36mBaseResourceVariable.assign_sub\u001b[0;34m(self, delta, use_locking, name, read_value)\u001b[0m\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;66;03m# TODO(apassos): this here and below is not atomic. Consider making it\u001b[39;00m\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;66;03m# atomic if there's a way to do so without a performance cost for those who\u001b[39;00m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;66;03m# don't need it.\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _handle_graph(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dependencies():\n\u001b[0;32m-> 1017\u001b[0m   assign_sub_op \u001b[38;5;241m=\u001b[39m gen_resource_variable_ops\u001b[38;5;241m.\u001b[39massign_sub_variable_op(\n\u001b[1;32m   1018\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m   1019\u001b[0m       ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(delta, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype),\n\u001b[1;32m   1020\u001b[0m       name\u001b[38;5;241m=\u001b[39mname)\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m read_value:\n\u001b[1;32m   1022\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lazy_read(assign_sub_op)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.17/lib/python3.9/contextlib.py:128\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen)\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt stop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training parameters\n",
    "epochs = 10000\n",
    "batch_size = 64\n",
    "save_interval = 1000  # Save the model every 1000 epochs\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    idx = np.random.randint(0, X_scaled.shape[0], batch_size)\n",
    "    real_data = X_scaled[idx]\n",
    "    wgan.train_step(real_data)\n",
    "\n",
    "    if epoch % save_interval == 0:\n",
    "        # Save the generator and critic models\n",
    "        generator.save(f'generator_epoch_{epoch}.h5')\n",
    "        critic.save(f'critic_epoch_{epoch}.h5')\n",
    "        print(f\"Epoch: {epoch} - Models saved\")\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f\"Epoch: {epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate new attack samples\n",
    "noise = np.random.normal(0, 1, (1000, 100))\n",
    "generated_data = generator.predict(noise)\n",
    "\n",
    "# Inverse transform to original scale\n",
    "generated_data = scaler.inverse_transform(generated_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "[[ 1.9448747e+05 -3.3237442e+02 -2.2459952e+07 ... -1.1344434e+05\n",
      "  -1.0402663e+06 -1.1324042e+06]\n",
      " [ 5.4202789e+04 -2.4433950e+03 -2.6691850e+08 ...  1.0283628e+05\n",
      "  -5.3337431e+05  2.4223880e+05]\n",
      " [ 5.2139688e+04  2.0000260e+04 -1.1424272e+08 ...  2.1217062e+05\n",
      "   8.8915994e+05  1.2470579e+05]\n",
      " ...\n",
      " [ 1.4361583e+05 -1.4197972e+03 -6.0625252e+07 ...  7.3155125e+04\n",
      "  -1.0520378e+06 -1.2970102e+06]\n",
      " [ 5.2146945e+04 -4.6831255e+03 -1.5843888e+08 ...  1.7122219e+05\n",
      "  -1.4363402e+06  3.5944553e+05]\n",
      " [ 1.3784159e+05  1.9480490e+03  9.2544368e+07 ...  4.2116504e+04\n",
      "  -3.1893928e+05 -4.5878822e+05]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# Load the saved generator model\n",
    "generator = tf.keras.models.load_model('generator_epoch_600.h5')\n",
    "\n",
    "# Load the scaler\n",
    "\n",
    "# Generate new attack samples\n",
    "noise = np.random.normal(0, 1, (1000, 100))\n",
    "generated_data = generator.predict(noise)\n",
    "\n",
    "# Inverse transform to original scale\n",
    "generated_data = scaler.inverse_transform(generated_data)\n",
    "\n",
    "# Convert the generated data to a DataFrame\n",
    "generated_df = pd.DataFrame(generated_data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "generated_df.to_csv('generated_attack_data.csv', index=False)\n",
    "\n",
    "# Print the generated data\n",
    "print(generated_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
